

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Graph Optimization Introduction &mdash; Intel® Low Precision Optimization Tool  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Intel® Low Precision Optimization Tool
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../welcome.html">Introduction to Intel LPOT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-documentation/api-introduction.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples_readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="doclist.html">Developer Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases_info.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributions.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../security_policy.html">Security Policy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Low Precision Optimization Tool</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Graph Optimization Introduction</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/docs/graph_optimization.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="graph-optimization-introduction">
<h1>Graph Optimization Introduction<a class="headerlink" href="#graph-optimization-introduction" title="Permalink to this headline">¶</a></h1>
<p>The graph optimization is mainly focus on below two kind of scenarios.</p>
<ol class="simple">
<li><p><strong>FP32 optimization</strong>. This is similar to TensorFlow optimization tool <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py">optimize_for_inference</a> while LPOT enables more optimizations (e.g., common subexpression elimination).</p></li>
<li><p><strong>Auto-mixed precision optimization</strong>. LPOT generates the optimal model with auto-mixed precision (<a class="reference external" href="https://cloud.google.com/tpu/docs/bfloat16">bfloat16</a> &amp; FP32) and allows the further auto-tuning per accuracy requirement.</p></li>
</ol>
</div>
<div class="section" id="how-to-use-it">
<h1>How to use it<a class="headerlink" href="#how-to-use-it" title="Permalink to this headline">¶</a></h1>
<p>Generally, we list below three examples to demonstrate the usage of graph optimization API.</p>
<div class="section" id="fp32-optimization">
<h2>1. <strong>FP32 Optimization</strong><a class="headerlink" href="#fp32-optimization" title="Permalink to this headline">¶</a></h2>
<p>LPOT would run graph optimization under FP32 optimization by default. In other words, it equals the user set the precisions to <strong>‘fp32’</strong> explicitly,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Graph_Optimization</span>
    <span class="n">graph_optimizer</span> <span class="o">=</span> <span class="n">Graph_Optimization</span><span class="p">()</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">precisions</span> <span class="o">=</span> <span class="s1">&#39;fp32&#39;</span> <span class="c1">#Optional, default is &#39;fp32&#39;</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="s1">&#39;input&#39;</span>  <span class="c1"># Optional</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="s1">&#39;op_to_store&#39;</span>  <span class="c1"># Optional</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/model&#39;</span>
    <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">graph_optimizer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="auto-mixed-precision-optimization">
<h2>2. <strong>Auto-mixed Precision Optimization</strong><a class="headerlink" href="#auto-mixed-precision-optimization" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="default-auto-mixed-precision">
<h2>2.1. <em>Default auto-mixed precision</em><a class="headerlink" href="#default-auto-mixed-precision" title="Permalink to this headline">¶</a></h2>
<p>The only difference between this and default mode is the <code class="docutils literal notranslate"><span class="pre">bf16</span></code> needs to be added into the precisions filed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Graph_Optimization</span>
    <span class="n">graph_optimizer</span> <span class="o">=</span> <span class="n">Graph_Optimization</span><span class="p">()</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">precisions</span> <span class="o">=</span> <span class="s1">&#39;bf16, fp32&#39;</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="s1">&#39;input&#39;</span>  <span class="c1"># Optional</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="s1">&#39;op_to_store&#39;</span>  <span class="c1"># Optional</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/model&#39;</span>
    <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">graph_optimizer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="auto-mixed-precision-with-auto-tuning">
<h2>2.2. <em>Auto-mixed precision with auto-tuning.</em><a class="headerlink" href="#auto-mixed-precision-with-auto-tuning" title="Permalink to this headline">¶</a></h2>
<p>LPOT also supports the tuning the model under graph optimization mode.
The end user need to replace the quantization field with graph_optimization parts like below. The precisions filed only supports ‘bf16’ and ‘fp32’.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">graph_optimization</span><span class="p">:</span>
  <span class="nt">precisions</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;bf16&#39;</span><span class="p p-Indicator">,</span> <span class="s">&#39;fp32&#39;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<p>Note, if we remove the evaluation field from the yaml, the graph optimization will only convert the model depends on the precisions setting.</p>
<p>When the graph_optimization field set and the evaluation field exists in the yaml, LPOT will execute the similar process like quantization. It means the LPOT would convert op into bf16 as much as possible and check the metric later, if the metric meet the criterion, the LPOT would exit or it would fallback one op to fp32 and re-run the above process till it meet the exit policy setting.</p>
<p>Below is the example of using the yaml to trigger the graph optimization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Graph_Optimization</span>
    <span class="n">graph_optimizer</span> <span class="o">=</span> <span class="n">Graph_Optimization</span><span class="p">(</span><span class="s1">&#39;/path/to/config.yaml&#39;</span><span class="p">)</span>
    <span class="n">graph_optimizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;/path/to/model&#39;</span>
    <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">graph_optimizer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Intel® LPOT.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>