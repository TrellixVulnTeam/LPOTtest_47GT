

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Dataset &mdash; Intel® Low Precision Optimization Tool  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorial" href="tutorial.html" />
    <link rel="prev" title="Transform" href="transform.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Intel® Low Precision Optimization Tool
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../welcome.html">Introduction to Intel LPOT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/readme.html">Examples</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="doclist.html">Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="doclist.html#getting-started">Getting Started</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="introduction.html">APIs</a></li>
<li class="toctree-l3"><a class="reference internal" href="transform.html">Transform</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#built-in-dataset-support-list">Built-in dataset support list</a></li>
<li class="toctree-l4"><a class="reference internal" href="#user-specific-dataset">User-specific dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html#usage-examples">Usage Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html#helloworld-examples">Helloworld Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="ux.html">Intel® Low Precision Optimization Tool UX</a></li>
<li class="toctree-l3"><a class="reference internal" href="ux.html#starting-the-ux">Starting the UX</a></li>
<li class="toctree-l3"><a class="reference internal" href="ux.html#my-models-list">My Models list</a></li>
<li class="toctree-l3"><a class="reference internal" href="ux.html#new-model-configuration-from-new-model-wizard">New Model Configuration from New Model Wizard</a></li>
<li class="toctree-l3"><a class="reference internal" href="ux.html#new-model-configuration-from-examples">New Model Configuration from Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="ux.html#custom-dataset-or-metric">Custom dataset or metric</a></li>
<li class="toctree-l3"><a class="reference internal" href="ux.html#tuning">Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="ux.html#advanced-options">Advanced options</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="doclist.html#deep-dive">Deep Dive</a></li>
<li class="toctree-l2"><a class="reference internal" href="doclist.html#advanced-topics">Advanced Topics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../releases-info.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">Contributing Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../SECURITY.html">Security Policy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Intel® Low Precision Optimization Tool</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="doclist.html">Documentation</a> &raquo;</li>
        
      <li>Dataset</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/docs/dataset.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="dataset">
<h1>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h1>
<p>Users can use LPOT built-in dataset objects as well as register their own datasets.</p>
<div class="section" id="built-in-dataset-support-list">
<h2>Built-in dataset support list<a class="headerlink" href="#built-in-dataset-support-list" title="Permalink to this headline">¶</a></h2>
<p>LPOT supports built-in dataloaders on popular industry datasets. Refer to ‘examples/helloworld/tf_example1’ to learn how to configure a built-in dataloader.</p>
<div class="section" id="tensorflow">
<h3>TensorFlow<a class="headerlink" href="#tensorflow" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Dataset</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MNIST(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/MNIST/, otherwise user should put mnist.npz under root/MNIST/ manually.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; MNIST: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['MNIST'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">FashionMNIST(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong>(bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/FashionMNIST/, otherwise user should put train-labels-idx1-ubyte.gz, train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; FashionMNIST: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['FashionMNIST'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">CIFAR10(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/ and extract it automatically, otherwise user can download file from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to root/ and extract it.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; CIFAR10: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['CIFAR10'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">CIFAR100(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/ and extract it automatically, otherwise user can download file from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to root/ and extract it.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; CIFAR100: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['CIFAR100'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">ImageRecord(root, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> root/validation-000-of-100 <br> root/validation-001-of-100 <br> ... <br> root/validation-099-of-100 <br> The file name needs to follow this pattern: '<em> - * -of- </em>'</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; ImageRecord: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['ImageRecord'] (root=root, transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">ImageFolder(root, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> root/class_1/xxx.png <br> root/class_1/xxy.png <br> root/class_1/xxz.png <br> ... <br> root/class_n/123.png <br> root/class_n/nsdf3.png <br> root/class_n/asd932_.png <br> Please put images of different categories into different folders.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; ImageFolder: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['ImageFolder'] (root=root,transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">ImagenetRaw(data_path, image_list, transform, filter)</td>
<td align="left"><strong>data_path</strong> (str): Root directory of dataset <br> <strong>image_list</strong> (str): data file, record image_names and their labels <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> data_path/img1.jpg <br> data_path/img2.jpg <br> ... <br> data_path/imgx.jpg <br> dataset will read name and label of each image from image_list file, if user set image_list to None, it will read from data_path/val_map.txt automatically.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; ImagenetRaw: <br> &ensp;&ensp;&ensp;&ensp; data_path: /path/to/image <br> &ensp;&ensp;&ensp;&ensp; image_list: /path/to/label <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['ImagenetRaw'] (data_path, image_list, transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">COCORecord(root, num_cores, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>num_cores</strong> (int, default=28):The number of input Datasets to interleave from in parallel <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Root is a full path to tfrecord file, which contains the file name. <br> <strong>COCORecord just supports batch_size=1</strong></td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; COCORecord: <br> &ensp;&ensp; root: /path/to/tfrecord <br> &ensp;&ensp; num_cores: 28 <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['COCORecord'] (root, num_cores=28, transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">COCORaw(root, img_dir, anno_dir, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>img_dir</strong> (str, default='val2017'): image file directory <br> <strong>anno_dir</strong> (str, default='annotations/instances_val2017.json'): annotation file directory <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> /root/img_dir/1.jpg <br> /root/img_dir/2.jpg <br> ... <br> /root/img_dir/n.jpg <br> /root/anno_dir <br> <strong>Now COCORaw just supports batch_size=1</strong></td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; COCORaw: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp; img_dir: /path/to/image <br> &ensp;&ensp; anno_dir: /path/to/annotation <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['COCORaw'] (root, img_dir, anno_dir, transform=transform, filter=None) <br> If anno_dir is not set, the dataset will use default label map</td>
</tr>
<tr>
<td align="left">dummy(shape, low, high, dtype, label, transform, filter)</td>
<td align="left"><strong>shape</strong> (list or tuple):support create multi shape tensors, use list of tuples for each tuple in the list, will create a such size tensor. <br> <strong>low</strong> (list or float, default=-128.):low out the tensor value range from[0, 1] to [0, low] or [low, 0] if low &lt; 0, if float, will implement all tensors with same low value. <br> <strong>high</strong> (list or float, default=127.):high the tensor value by add all tensor element value high. If list, length of list should be same with shape list <br> <strong>dtype</strong> (list or str, default='float32'):support multi tensor dtype setting. If list, length of list should be same with shape list, if str, all tensors will use same dtype. dtype support 'float32', 'float16', 'uint8', 'int8', 'int32', 'int64', 'bool' <br> <strong>label</strong> (bool, default=False):whether to return 0 as label <br> <strong>transform</strong> (transform object, default=None): dummy dataset does not need transform. If transform is not None, it will ignore it. <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">This dataset is to construct a dataset from a specific shape, the value range is calculated from: low * stand_normal(0, 1) + high.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; dummy: <br> &ensp;&ensp;&ensp;&ensp; shape: [3, 224, 224, 3] <br> &ensp;&ensp;&ensp;&ensp; low: 0.0 <br> &ensp;&ensp;&ensp;&ensp; high: 127.0 <br> &ensp;&ensp;&ensp;&ensp; dtype: float32 <br> &ensp;&ensp;&ensp;&ensp; label: False <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['dummy'] (shape, low, high, dtype, label, transform=None, filter=None)</td>
</tr>
<tr>
<td align="left">style_transfer(content_folder, style_folder, crop_ratio, resize_shape, image_format, transform, filter)</td>
<td align="left"><strong>content_folder</strong> (str):Root directory of content images <br> <strong>style_folder</strong> (str):Root directory of style images <br> <strong>crop_ratio</strong> (float, default=0.1):cropped ratio to each side <br> <strong>resize_shape</strong> (tuple, default=(256, 256)):target size of image <br> <strong>image_format</strong> (str, default='jpg'): target image format <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Dataset used for style transfer task. This Dataset is to construct a dataset from two specific image holders representing content image folder and style image folder.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; style_transfer: <br> &ensp;&ensp;&ensp;&ensp; content_folder: /path/to/content_folder <br> &ensp;&ensp;&ensp;&ensp; style_folder: /path/to/style_folder <br> &ensp;&ensp;&ensp;&ensp; crop_ratio: 0.1 <br> &ensp;&ensp;&ensp;&ensp; resize_shape: [256, 256] <br> &ensp;&ensp;&ensp;&ensp; image_format: 'jpg' <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['style_transfer'] (content_folder, style_folder, crop_ratio, resize_shape, image_format, transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">TFRecordDataset(root, compression_type, buffer_size, num_parallel_reads, transform, filter)</td>
<td align="left"><strong>root</strong> (str): filename of dataset <br> <strong>compression_type</strong> (str, default=None):compression type, support "" (no compression), "ZLIB", or "GZIP". <br> <strong>buffer_size</strong> (int, default=None): the number of bytes in the read buffer <br> <strong>num_parallel_reads</strong> (tint, default=None): the number of files to read in parallel <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Root is a full path to tfrecord file, which contains the file name.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; TFRecordDataset: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/tfrecord <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['TFRecordDataset'] (root, transform=transform)</td>
</tr>
<tr>
<td align="left">bert(root, label_file, task, transform, filter)</td>
<td align="left"><strong>root</strong> (str): path of dataset <br> <strong>label_file</strong> (str): path of label file <br> <strong>task</strong> (str, default='squad'): task type of model <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">This dataset supports tfrecord data, please refer to <a href="../examples/tensorflow/nlp/bert/README.md">Guide</a> to create tfrecord file first.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; bert: <br> &ensp;&ensp; root: /path/to/root <br> &ensp;&ensp; label_file: /path/to/label_file <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['bert'] (root, label_file, transform=transform)</td>
</tr>
</tbody>
</table></div>
<div class="section" id="pytorch">
<h3>PyTorch<a class="headerlink" href="#pytorch" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Dataset</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MNIST(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/MNIST/, otherwise user should put mnist.npz under root/MNIST/ manually.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; MNIST: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['MNIST'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">FashionMNIST(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong>(bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/FashionMNIST/, otherwise user should put train-labels-idx1-ubyte.gz, train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; FashionMNIST: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['FashionMNIST'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">CIFAR10(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/ and extract it automatically, otherwise user can download file from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to root/ and extract it.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; CIFAR10: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['CIFAR10'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">CIFAR100(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/ and extract it automatically, otherwise user can download file from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to root/ and extract it.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; CIFAR100: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['CIFAR100'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">ImageFolder(root, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> root/class_1/xxx.png <br> root/class_1/xxy.png <br> root/class_1/xxz.png <br> ... <br> root/class_n/123.png <br> root/class_n/nsdf3.png <br> root/class_n/asd932_.png <br> Please put images of different categories into different folders.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; ImageFolder: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['ImageFolder'] (root=root,transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">ImagenetRaw(data_path, image_list, transform, filter)</td>
<td align="left"><strong>data_path</strong> (str): Root directory of dataset <br> <strong>image_list</strong> (str): data file, record image_names and their labels <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> data_path/img1.jpg <br> data_path/img2.jpg <br> ... <br> data_path/imgx.jpg <br> dataset will read name and label of each image from image_list file, if user set image_list to None, it will read from data_path/val_map.txt automatically.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; ImagenetRaw: <br> &ensp;&ensp;&ensp;&ensp; data_path: /path/to/image <br> &ensp;&ensp;&ensp;&ensp; image_list: /path/to/label <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['ImagenetRaw'] (data_path, image_list, transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">COCORaw(root, img_dir, anno_dir, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>img_dir</strong> (str, default='val2017'): image file directory <br> <strong>anno_dir</strong> (str, default='annotations/instances_val2017.json'): annotation file directory <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> /root/img_dir/1.jpg <br> /root/img_dir/2.jpg <br> ... <br> /root/img_dir/n.jpg <br> /root/anno_dir <br> <strong>Now COCORaw just supports batch_size=1</strong></td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; COCORaw: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp; img_dir: /path/to/image <br> &ensp;&ensp; anno_dir: /path/to/annotation <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['COCORaw'] (root, img_dir, anno_dir, transform=transform, filter=None) <br> If anno_dir is not set, the dataset will use default label map</td>
</tr>
<tr>
<td align="left">dummy(shape, low, high, dtype, label, transform, filter)</td>
<td align="left"><strong>shape</strong> (list or tuple):support create multi shape tensors, use list of tuples for each tuple in the list, will create a such size tensor. <br> <strong>low</strong> (list or float, default=-128.):low out the tensor value range from[0, 1] to [0, low] or [low, 0] if low &lt; 0, if float, will implement all tensors with same low value. <br> <strong>high</strong> (list or float, default=127.):high the tensor value by add all tensor element value high. If list, length of list should be same with shape list <br> <strong>dtype</strong> (list or str, default='float32'):support multi tensor dtype setting. If list, length of list should be same with shape list, if str, all tensors will use same dtype. dtype support 'float32', 'float16', 'uint8', 'int8', 'int32', 'int64', 'bool' <br> <strong>label</strong> (bool, default=False):whether to return 0 as label <br> <strong>transform</strong> (transform object, default=None): dummy dataset does not need transform. If transform is not None, it will ignore it. <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">This dataset is to construct a dataset from a specific shape, the value range is calculated from: low * stand_normal(0, 1) + high.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; dummy: <br> &ensp;&ensp;&ensp;&ensp; shape: [3, 224, 224, 3] <br> &ensp;&ensp;&ensp;&ensp; low: 0.0 <br> &ensp;&ensp;&ensp;&ensp; high: 127.0 <br> &ensp;&ensp;&ensp;&ensp; dtype: float32 <br> &ensp;&ensp;&ensp;&ensp; label: False <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['dummy'] (shape, low, high, dtype, label, transform=None, filter=None)</td>
</tr>
<tr>
<td align="left">bert(dataset, task, model_type, transform, filter)</td>
<td align="left"><strong>dataset</strong> (list): list of data <br> <strong>task</strong> (str): the task of the model, support "classifier", "squad" <br> <strong>model_type</strong> (str, default='bert'): model type, support 'distilbert', 'bert', 'xlnet', 'xlm' <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">This Dataset is to construct from the Bert TensorDataset and not a full implementation from yaml config. The original repo link is: https://github.com/huggingface/transformers. When you want use this Dataset, you should add it before you initialize your DataLoader.</td>
<td align="left"><strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets<a href="dataset, task, model_type, transform=transform, filter=None">'bert'</a> <br> Now not support yaml implementation</td>
</tr>
</tbody>
</table></div>
<div class="section" id="mxnet">
<h3>MXNet<a class="headerlink" href="#mxnet" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Dataset</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MNIST(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/MNIST/, otherwise user should put mnist.npz under root/MNIST/ manually.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; MNIST: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['MNIST'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">FashionMNIST(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong>(bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/FashionMNIST/, otherwise user should put train-labels-idx1-ubyte.gz, train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; FashionMNIST: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['FashionMNIST'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">CIFAR10(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/ and extract it automatically, otherwise user can download file from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to root/ and extract it.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; CIFAR10: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['CIFAR10'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">CIFAR100(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/ and extract it automatically, otherwise user can download file from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to root/ and extract it.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; CIFAR100: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['CIFAR100'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">ImageFolder(root, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> root/class_1/xxx.png <br> root/class_1/xxy.png <br> root/class_1/xxz.png <br> ... <br> root/class_n/123.png <br> root/class_n/nsdf3.png <br> root/class_n/asd932_.png <br> Please put images of different categories into different folders.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; ImageFolder: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['ImageFolder'] (root=root,transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">ImagenetRaw(data_path, image_list, transform, filter)</td>
<td align="left"><strong>data_path</strong> (str): Root directory of dataset <br> <strong>image_list</strong> (str): data file, record image_names and their labels <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> data_path/img1.jpg <br> data_path/img2.jpg <br> ... <br> data_path/imgx.jpg <br> dataset will read name and label of each image from image_list file, if user set image_list to None, it will read from data_path/val_map.txt automatically.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; ImagenetRaw: <br> &ensp;&ensp;&ensp;&ensp; data_path: /path/to/image <br> &ensp;&ensp;&ensp;&ensp; image_list: /path/to/label <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['ImagenetRaw'] (data_path, image_list, transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">COCORaw(root, img_dir, anno_dir, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>img_dir</strong> (str, default='val2017'): image file directory <br> <strong>anno_dir</strong> (str, default='annotations/instances_val2017.json'): annotation file directory <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> /root/img_dir/1.jpg <br> /root/img_dir/2.jpg <br> ... <br> /root/img_dir/n.jpg <br> /root/anno_dir <br> <strong>Now COCORaw just supports batch_size=1</strong></td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; COCORaw: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp; img_dir: /path/to/image <br> &ensp;&ensp; anno_dir: /path/to/annotation <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['COCORaw'] (root, img_dir, anno_dir, transform=transform, filter=None) <br> If anno_dir is not set, the dataset will use default label map</td>
</tr>
<tr>
<td align="left">dummy(shape, low, high, dtype, label, transform, filter)</td>
<td align="left"><strong>shape</strong> (list or tuple):support create multi shape tensors, use list of tuples for each tuple in the list, will create a such size tensor. <br> <strong>low</strong> (list or float, default=-128.):low out the tensor value range from[0, 1] to [0, low] or [low, 0] if low &lt; 0, if float, will implement all tensors with same low value. <br> <strong>high</strong> (list or float, default=127.):high the tensor value by add all tensor element value high. If list, length of list should be same with shape list <br> <strong>dtype</strong> (list or str, default='float32'):support multi tensor dtype setting. If list, length of list should be same with shape list, if str, all tensors will use same dtype. dtype support 'float32', 'float16', 'uint8', 'int8', 'int32', 'int64', 'bool' <br> <strong>label</strong> (bool, default=False):whether to return 0 as label <br> <strong>transform</strong> (transform object, default=None): dummy dataset does not need transform. If transform is not None, it will ignore it. <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">This dataset is to construct a dataset from a specific shape, the value range is calculated from: low * stand_normal(0, 1) + high.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; dummy: <br> &ensp;&ensp;&ensp;&ensp; shape: [3, 224, 224, 3] <br> &ensp;&ensp;&ensp;&ensp; low: 0.0 <br> &ensp;&ensp;&ensp;&ensp; high: 127.0 <br> &ensp;&ensp;&ensp;&ensp; dtype: float32 <br> &ensp;&ensp;&ensp;&ensp; label: False <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['dummy'] (shape, low, high, dtype, label, transform=None, filter=None)</td>
</tr>
</tbody>
</table></div>
<div class="section" id="onnxrt">
<h3>ONNXRT<a class="headerlink" href="#onnxrt" title="Permalink to this headline">¶</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th align="left">Dataset</th>
<th align="left">Parameters</th>
<th align="left">Comments</th>
<th align="left">Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MNIST(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/MNIST/, otherwise user should put mnist.npz under root/MNIST/ manually.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; MNIST: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['MNIST'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">FashionMNIST(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong>(bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/FashionMNIST/, otherwise user should put train-labels-idx1-ubyte.gz, train-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz and t10k-images-idx3-ubyte.gz under root/FashionMNIST/ manually.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; FashionMNIST: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['FashionMNIST'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">CIFAR10(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/ and extract it automatically, otherwise user can download file from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz manually to root/ and extract it.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; CIFAR10: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['CIFAR10'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">CIFAR100(root, train, transform, filter, download)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>train</strong> (bool, default=False): If True, creates dataset from train subset, otherwise from validation subset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions <br> <strong>download</strong> (bool, default=True): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.</td>
<td align="left">If download is True, it will download dataset to root/ and extract it automatically, otherwise user can download file from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz manually to root/ and extract it.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; CIFAR100: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp;&ensp;&ensp; train: False <br> &ensp;&ensp;&ensp;&ensp; download: True <br> (transform and filter are not set in the range of dataset) <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['CIFAR100'] (root=root, train=False, transform=transform, filter=None, download=True)</td>
</tr>
<tr>
<td align="left">ImageFolder(root, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> root/class_1/xxx.png <br> root/class_1/xxy.png <br> root/class_1/xxz.png <br> ... <br> root/class_n/123.png <br> root/class_n/nsdf3.png <br> root/class_n/asd932_.png <br> Please put images of different categories into different folders.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; ImageFolder: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['ImageFolder'] (root=root,transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">ImagenetRaw(data_path, image_list, transform, filter)</td>
<td align="left"><strong>data_path</strong> (str): Root directory of dataset <br> <strong>image_list</strong> (str): data file, record image_names and their labels <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> data_path/img1.jpg <br> data_path/img2.jpg <br> ... <br> data_path/imgx.jpg <br> dataset will read name and label of each image from image_list file, if user set image_list to None, it will read from data_path/val_map.txt automatically.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; ImagenetRaw: <br> &ensp;&ensp;&ensp;&ensp; data_path: /path/to/image <br> &ensp;&ensp;&ensp;&ensp; image_list: /path/to/label <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['ImagenetRaw'] (data_path, image_list, transform=transform, filter=None)</td>
</tr>
<tr>
<td align="left">COCORaw(root, img_dir, anno_dir, transform, filter)</td>
<td align="left"><strong>root</strong> (str): Root directory of dataset <br> <strong>img_dir</strong> (str, default='val2017'): image file directory <br> <strong>anno_dir</strong> (str, default='annotations/instances_val2017.json'): annotation file directory <br> <strong>transform</strong> (transform object, default=None):  transform to process input data <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">Please arrange data in this way: <br> /root/img_dir/1.jpg <br> /root/img_dir/2.jpg <br> ... <br> /root/img_dir/n.jpg <br> /root/anno_dir <br> <strong>Now COCORaw just supports batch_size=1</strong></td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; COCORaw: <br> &ensp;&ensp;&ensp;&ensp; root: /path/to/root <br> &ensp;&ensp; img_dir: /path/to/image <br> &ensp;&ensp; anno_dir: /path/to/annotation <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['COCORaw'] (root, img_dir, anno_dir, transform=transform, filter=None) <br> If anno_dir is not set, the dataset will use default label map</td>
</tr>
<tr>
<td align="left">dummy(shape, low, high, dtype, label, transform, filter)</td>
<td align="left"><strong>shape</strong> (list or tuple):support create multi shape tensors, use list of tuples for each tuple in the list, will create a such size tensor. <br> <strong>low</strong> (list or float, default=-128.):low out the tensor value range from[0, 1] to [0, low] or [low, 0] if low &lt; 0, if float, will implement all tensors with same low value. <br> <strong>high</strong> (list or float, default=127.):high the tensor value by add all tensor element value high. If list, length of list should be same with shape list <br> <strong>dtype</strong> (list or str, default='float32'):support multi tensor dtype setting. If list, length of list should be same with shape list, if str, all tensors will use same dtype. dtype support 'float32', 'float16', 'uint8', 'int8', 'int32', 'int64', 'bool' <br> <strong>label</strong> (bool, default=False):whether to return 0 as label <br> <strong>transform</strong> (transform object, default=None): dummy dataset does not need transform. If transform is not None, it will ignore it. <br> <strong>filter</strong> (Filter objects, default=None): filter out examples according to specific conditions</td>
<td align="left">This dataset is to construct a dataset from a specific shape, the value range is calculated from: low * stand_normal(0, 1) + high.</td>
<td align="left"><strong>In yaml file:</strong> <br> dataset: <br> &ensp;&ensp; dummy: <br> &ensp;&ensp;&ensp;&ensp; shape: [3, 224, 224, 3] <br> &ensp;&ensp;&ensp;&ensp; low: 0.0 <br> &ensp;&ensp;&ensp;&ensp; high: 127.0 <br> &ensp;&ensp;&ensp;&ensp; dtype: float32 <br> &ensp;&ensp;&ensp;&ensp; label: False <br> <strong>In user code:</strong> <br> from lpot.data import DATASETS <br> datasets = DATASETS(framework) <br> dataset = datasets['dummy'] (shape, low, high, dtype, label, transform=None, filter=None)</td>
</tr>
</tbody>
</table></div>
</div>
<div class="section" id="user-specific-dataset">
<h2>User-specific dataset<a class="headerlink" href="#user-specific-dataset" title="Permalink to this headline">¶</a></h2>
<p>Users can register their own datasets as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Dataset</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="c1"># init code here</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="c1"># use idx to get data and label</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">label</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span>
</pre></div>
</div>
<p>After defining the dataset class, pass it to the quantizer:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">lpot</span> <span class="kn">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">(</span><span class="n">yaml_file</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">calib_dataloader</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="c1"># user can pass more optional args to dataloader such as batch_size and collate_fn</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">eval_func</span> <span class="o">=</span> <span class="n">eval_func</span>
<span class="n">q_model</span> <span class="o">=</span> <span class="n">quantizer</span><span class="p">()</span> 
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="tutorial.html" class="btn btn-neutral float-right" title="Tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="transform.html" class="btn btn-neutral float-left" title="Transform" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Intel® LPOT.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>