

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>MLPerf Inference - Speech Recognition - RNN-T &mdash; Intel® Low Precision Optimization Tool  documentation</title>
  

  
  <link rel="stylesheet" href="../../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../../" src="../../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../../_static/jquery.js"></script>
        <script src="../../../../../../_static/underscore.js"></script>
        <script src="../../../../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../../index.html" class="icon icon-home"> Intel® Low Precision Optimization Tool
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../welcome.html">Introduction to Intel LPOT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../docs/introduction.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../docs/index.html">Developer Docs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../CONTRIBUTING.html">Contributing Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../SECURITY.html">Security Policy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">Intel® Low Precision Optimization Tool</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>MLPerf Inference - Speech Recognition - RNN-T</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../../../../_sources/examples/pytorch/speech_recognition/inference/rnnt/optional_harness_ck/README.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mlperf-inference-speech-recognition-rnn-t">
<h1>MLPerf Inference - Speech Recognition - RNN-T<a class="headerlink" href="#mlperf-inference-speech-recognition-rnn-t" title="Permalink to this headline">¶</a></h1>
<p>We describe an automated and reproducible workflow for the <a class="reference external" href="https://github.com/mlperf/inference/tree/master/v0.7/speech_recognition/rnnt">RNN-T
workload</a>
implemented using the <a class="reference external" href="http://cknowledge.org">Collective Knowledge</a> technology. It automatically
downloads the model and the dataset, preprocesses the dataset, builds the LoadGen API, etc.
For any questions or questions, please email info&#64;dividiti.com or simply <a class="reference external" href="https://github.com/mlperf/inference/issues">open an issue</a> on GitHub.</p>
<p><strong>NB:</strong> Below we give an <em>essential</em> sequence of steps that should result in a successful setup
of the RNN-T workflow on a minimally configured Linux system.</p>
<p>The steps are extracted from a <a class="reference external" href="https://github.com/ctuning/ck-mlperf/blob/master/docker/speech-recognition.rnnt/Dockerfile.amazonlinux.min">minimalistic Amazon Linux
2</a>
Docker image, which is derived from a more verbose <a class="reference external" href="https://github.com/ctuning/ck-mlperf/blob/master/docker/speech-recognition.rnnt/Dockerfile.amazonlinux">Amazon Linux
2</a>
Docker image by omitting steps that the <a class="reference external" href="https://github.com/ctuning/ck">Collective Knowledge
framework</a> performs automatically.</p>
<p>For example, installing the preprocessed dataset is explicit in the verbose image:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#-----------------------------------------------------------------------------#</span>
<span class="c1"># Step 3. Download the official MLPerf Inference RNNT dataset (LibriSpeech</span>
<span class="c1"># dev-clean) and preprocess it to wav.</span>
<span class="c1">#-----------------------------------------------------------------------------#</span>
<span class="n">RUN</span> <span class="n">ck</span> <span class="n">install</span> <span class="n">package</span> <span class="o">--</span><span class="n">tags</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span><span class="n">speech</span><span class="o">-</span><span class="n">recognition</span><span class="p">,</span><span class="n">dev</span><span class="o">-</span><span class="n">clean</span><span class="p">,</span><span class="n">original</span>
<span class="c1"># NB: Can ignore the lzma related warning.</span>
<span class="n">RUN</span> <span class="n">ck</span> <span class="n">install</span> <span class="n">package</span> <span class="o">--</span><span class="n">tags</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span><span class="n">speech</span><span class="o">-</span><span class="n">recognition</span><span class="p">,</span><span class="n">dev</span><span class="o">-</span><span class="n">clean</span><span class="p">,</span><span class="n">preprocessed</span>
<span class="c1">#-----------------------------------------------------------------------------#</span>
</pre></div>
</div>
<p>but is implicit in the minimalistic image:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#- #-----------------------------------------------------------------------------#</span>
<span class="c1">#- # Step 3. Download the official MLPerf Inference RNNT dataset (LibriSpeech</span>
<span class="c1">#- # dev-clean) and preprocess it to wav.</span>
<span class="c1">#- #-----------------------------------------------------------------------------#</span>
<span class="c1">#- RUN ck install package --tags=dataset,speech-recognition,dev-clean,original</span>
<span class="c1">#- # NB: Can ignore the  lzma related warning.</span>
<span class="c1">#- RUN ck install package --tags=dataset,speech-recognition,dev-clean,preprocessed</span>
<span class="c1">#- #-----------------------------------------------------------------------------#</span>
</pre></div>
</div>
<p>because it’s going to be triggered by a test performance run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#+ #-----------------------------------------------------------------------------#</span>
<span class="c1">#+ # Step 6. Pull all the implicit dependencies commented out in Steps 1-5.</span>
<span class="c1">#+ #-----------------------------------------------------------------------------#</span>
<span class="n">RUN</span> <span class="n">ck</span> <span class="n">run</span> <span class="n">program</span><span class="p">:</span><span class="n">speech</span><span class="o">-</span><span class="n">recognition</span><span class="o">-</span><span class="n">pytorch</span><span class="o">-</span><span class="n">loadgen</span> <span class="o">--</span><span class="n">cmd_key</span><span class="o">=</span><span class="n">performance</span> <span class="o">--</span><span class="n">skip_print_timers</span>
<span class="c1">#+ #-----------------------------------------------------------------------------#</span>
</pre></div>
</div>
<p>(Omitted steps are commented out with <code class="docutils literal notranslate"><span class="pre">#-</span> </code>. Added steps are commented with <code class="docutils literal notranslate"><span class="pre">#+</span> </code>.)</p>
<p>For other possible variations and workarounds see the <a class="reference external" href="https://github.com/ctuning/ck-mlperf/blob/master/docker/speech-recognition.rnnt/README.md">complete
collection</a>
of Docker images for this workflow including Ubuntu, Debian and CentOS.</p>
</div>
<div class="section" id="table-of-contents">
<h1>Table of Contents<a class="headerlink" href="#table-of-contents" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p><a class="reference external" href="#install">Installation</a></p>
<ol class="simple">
<li><p>Install <a class="reference external" href="#install_system">system-wide prerequisites</a></p>
<ol class="simple">
<li><p><a class="reference external" href="#install_system_ubuntu">Ubuntu 20.04 or similar</a></p></li>
<li><p><a class="reference external" href="#install_system_centos_7">CentOS 7 or similar</a></p></li>
<li><p><a class="reference external" href="#install_system_centos_8">CentOS 8 or similar</a></p></li>
</ol>
</li>
<li><p>Install <a class="reference external" href="#install_ck">Collective Knowledge</a> (CK) and its repositories</p></li>
<li><p>Detect <a class="reference external" href="#detect_gcc">GCC</a></p></li>
<li><p>Detect <a class="reference external" href="#detect_python">Python</a></p></li>
<li><p>Install <a class="reference external" href="#install_python_deps">Python dependencies</a></p></li>
<li><p>Install a branch of the <a class="reference external" href="#install_inference_repo">MLPerf Inference</a> repo</p></li>
</ol>
</li>
<li><p><a class="reference external" href="#usage">Usage</a></p>
<ol class="simple">
<li><p><a class="reference external" href="#usage_performance">Performance</a></p></li>
<li><p><a class="reference external" href="#usage_performance">Accuracy</a></p></li>
</ol>
</li>
</ol>
<p><a name="install"></a></p>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p><a name="install_system"></a></p>
<div class="section" id="install-system-wide-prerequisites">
<h3>Install system-wide prerequisites<a class="headerlink" href="#install-system-wide-prerequisites" title="Permalink to this headline">¶</a></h3>
<p><strong>NB:</strong> Run the below commands for your Linux system with <code class="docutils literal notranslate"><span class="pre">sudo</span></code> or as superuser.</p>
<p><a name="install_system_ubuntu"></a></p>
<div class="section" id="ubuntu-20-04-or-similar">
<h4>Ubuntu 20.04 or similar<a class="headerlink" href="#ubuntu-20-04-or-similar" title="Permalink to this headline">¶</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ sudo apt update -y
$ sudo apt install -y apt-utils
$ sudo apt upgrade -y
$ sudo apt install -y<span class="se">\</span>
 python3 python3-pip<span class="se">\</span>
 gcc g++<span class="se">\</span>
 make patch vim<span class="se">\</span>
 git wget zip libz-dev<span class="se">\</span>
 libsndfile1-dev
$ sudo apt clean
</pre></div>
</div>
<p><a name="install_system_centos_7"></a></p>
</div>
<div class="section" id="centos-7-or-similar">
<h4>CentOS 7 or similar<a class="headerlink" href="#centos-7-or-similar" title="Permalink to this headline">¶</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ sudo yum upgrade -y
$ sudo yum install -y<span class="se">\</span>
 python3 python3-pip python3-devel<span class="se">\</span>
 gcc gcc-c++<span class="se">\</span>
 make which patch vim<span class="se">\</span>
 git wget zip unzip<span class="se">\</span>
 tar xz<span class="se">\</span>
 libsndfile-devel
$ sudo yum clean all
</pre></div>
</div>
<p><a name="install_system_centos_8"></a></p>
</div>
<div class="section" id="centos-8-or-similar">
<h4>CentOS 8 or similar<a class="headerlink" href="#centos-8-or-similar" title="Permalink to this headline">¶</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ sudo yum upgrade -y
$ sudo yum install -y<span class="se">\</span>
 gcc gcc-c++<span class="se">\</span>
 make which patch vim<span class="se">\</span>
 git wget zip unzip<span class="se">\</span>
 openssl-devel bzip2-devel libffi-devel<span class="se">\</span>
$ sudo yum clean all
$ sudo dnf install -y python3 python3-pip python3-devel
$ sudo dnf --enablerepo<span class="o">=</span>PowerTools install -y libsndfile-devel
</pre></div>
</div>
<p><a name="install_ck"></a></p>
</div>
</div>
<div class="section" id="install-collective-knowledge-ck-and-its-repositories">
<h3>Install <a class="reference external" href="http://cknowledge.org/">Collective Knowledge</a> (CK) and its repositories<a class="headerlink" href="#install-collective-knowledge-ck-and-its-repositories" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">CK_PYTHON</span><span class="o">=</span>/usr/bin/python3
$ <span class="nv">$CK_PYTHON</span> -m pip install --ignore-installed pip setuptools --user
$ <span class="nv">$CK_PYTHON</span> -m pip install ck
$ ck version
V1.15.0
$ ck pull repo:ck-mlperf
$ ck pull repo:ck-pytorch
</pre></div>
</div>
<p><a name="detect_gcc"></a></p>
</div>
<div class="section" id="detect-system-gcc">
<h3>Detect (system) GCC<a class="headerlink" href="#detect-system-gcc" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ export CK_CC=/usr/bin/gcc
$ ck detect soft:compiler.gcc --full_path=$CK_CC
$ ck show env --tags=compiler,gcc
Env UID:         Target OS: Bits: Name:          Version: Tags:

b8bd7b49f72f9794   linux-64    64 GNU C compiler 7.3.1    64bits,compiler,gcc,host-os-linux-64,lang-c,lang-cpp,target-os-linux-64,v7,v7.3,v7.3.1
</pre></div>
</div>
<p><strong>NB:</strong> Required to build the FLAC and SoX dependencies of preprocessing. CK can normally detect compilers automatically, but we are playing safe here.</p>
<p><a name="detect_python"></a></p>
</div>
<div class="section" id="detect-system-python">
<h3>Detect (system) Python<a class="headerlink" href="#detect-system-python" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ export CK_PYTHON=/usr/bin/python3
$ ck detect soft:compiler.python --full_path=$CK_PYTHON
$ ck show env --tags=compiler,python
Env UID:         Target OS: Bits: Name:  Version: Tags:

633a6b22205eb07f   linux-64    64 python 3.7.6    64bits,compiler,host-os-linux-64,lang-python,python,target-os-linux-64,v3,v3.7,v3.7.6
</pre></div>
</div>
<p><strong>NB:</strong> CK can normally detect available Python interpreters automatically, but we are playing safe here.</p>
<p><a name="install_python_deps"></a></p>
</div>
<div class="section" id="install-python-dependencies-in-userspace">
<h3>Install Python dependencies (in userspace)<a class="headerlink" href="#install-python-dependencies-in-userspace" title="Permalink to this headline">¶</a></h3>
<div class="section" id="install-implicit-dependencies-via-pip">
<h4>Install implicit dependencies via pip<a class="headerlink" href="#install-implicit-dependencies-via-pip" title="Permalink to this headline">¶</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">CK_PYTHON</span><span class="o">=</span>/usr/bin/python3
$ <span class="nv">$CK_PYTHON</span> -m pip install --user --upgrade <span class="se">\</span>
  tqdm wheel toml unidecode inflect sndfile librosa <span class="nv">numba</span><span class="o">==</span><span class="m">0</span>.48
...
Successfully installed inflect-4.1.0 librosa-0.7.2 llvmlite-0.31.0 numba-0.48.0 sndfile-0.2.0 unidecode-1.1.1 wheel-0.34.2
</pre></div>
</div>
<p><strong>NB:</strong> These dependencies are <em>implicit</em>, i.e. CK will not try to satisfy them. If they are not installed, however, the workflow will fail.</p>
</div>
<div class="section" id="install-explicit-dependencies-via-ck-also-via-pip-but-register-with-ck-at-the-same-time">
<h4>Install explicit dependencies via CK (also via <code class="docutils literal notranslate"><span class="pre">pip</span></code>, but register with CK at the same time)<a class="headerlink" href="#install-explicit-dependencies-via-ck-also-via-pip-but-register-with-ck-at-the-same-time" title="Permalink to this headline">¶</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ck install package --tags<span class="o">=</span>python-package,torch
$ ck install package --tags<span class="o">=</span>python-package,pandas
$ ck install package --tags<span class="o">=</span>python-package,sox
$ ck install package --tags<span class="o">=</span>python-package,absl
</pre></div>
</div>
<p><strong>NB:</strong> These dependencies are <em>explicit</em>, i.e. CK will try to satisfy them automatically. On a machine with multiple versions of Python, things can get messy, so we are playing safe here.</p>
<p><a name="install_inference_repo"></a></p>
</div>
</div>
<div class="section" id="install-an-mlperf-inference-branch-with-dividiti-s-tweaks-for-rnn-t">
<h3>Install an MLPerf Inference <a class="reference external" href="https://github.com/dividiti/inference/tree/dvdt-rnnt">branch</a> with <a class="reference external" href="http://dividiti.com">dividiti</a>’s tweaks for RNN-T<a class="headerlink" href="#install-an-mlperf-inference-branch-with-dividiti-s-tweaks-for-rnn-t" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ ck install package --tags<span class="o">=</span>mlperf,inference,source,dividiti.rnnt
</pre></div>
</div>
<p><strong>NB:</strong> This source will be used for building LoadGen as well.</p>
<p><a name="usage"></a></p>
</div>
</div>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h2>
<p><a name="usage_performance"></a></p>
<div class="section" id="running-a-performance-test">
<h3>Running a performance test<a class="headerlink" href="#running-a-performance-test" title="Permalink to this headline">¶</a></h3>
<p>The first run will end up resolving all the remaining explicit dependencies:</p>
<ul class="simple">
<li><p>preprocessing the LibriSpeech Dev-Clean dataset to wav;</p></li>
<li><p>building the LoadGen API;</p></li>
<li><p>downloading the PyTorch model.</p></li>
</ul>
<p>It’s a performance run which should print something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ck run program:speech-recognition-pytorch-loadgen --cmd_key=performance --skip_print_timers
...
Dataset loaded with 4.36 hours. Filtered 1.02 hours. Number of samples: 2513
Running Loadgen test...
Average latency (ms) per query:
7335.167247106061
Median latency (ms):
7391.662108
90 percentile latency (ms):
13347.925176
================================================
MLPerf Results Summary
================================================
SUT name : PySUT
Scenario : Offline
Mode     : Performance
Samples per second: 4.63626
Result is : INVALID
  Min duration satisfied : NO
  Min queries satisfied : Yes
Recommendations:
 * Increase expected QPS so the loadgen pre-generates a larger (coalesced) query.

================================================
Additional Stats
================================================
Min latency (ns)                : 278432559
Max latency (ns)                : 14235613054
Mean latency (ns)               : 7335167247
50.00 percentile latency (ns)   : 7521181269
90.00 percentile latency (ns)   : 13402430910
95.00 percentile latency (ns)   : 13723706550
97.00 percentile latency (ns)   : 14054764438
99.00 percentile latency (ns)   : 14235613054
99.90 percentile latency (ns)   : 14235613054

================================================
Test Parameters Used
================================================
samples_per_query : 66
target_qps : 1
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 60000
max_duration (ms): 0
min_query_count : 1
max_query_count : 0
qsl_rng_seed : 3133965575612453542
sample_index_rng_seed : 665484352860916858
schedule_rng_seed : 3622009729038561421
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
print_timestamps : false
performance_issue_unique : false
performance_issue_same : false
performance_issue_same_index : 0
performance_sample_count : 2513

No warnings encountered during test.

No errors encountered during test.
Done!

Execution time: 38.735 sec.
</pre></div>
</div>
<p>The above output is the contents of <code class="docutils literal notranslate"><span class="pre">mlperf_log_summary.txt</span></code>, one of the log files generated by LoadGen. All LoadGen log files can be located in the program’s temporary directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">cd</span> <span class="sb">`</span>ck find program:speech-recognition-pytorch-loadgen<span class="sb">`</span>/tmp <span class="o">&amp;&amp;</span> ls -la mlperf_log_*
-rw-r--r-- <span class="m">1</span> anton eng      <span class="m">4</span> Jul  <span class="m">3</span> <span class="m">18</span>:06 mlperf_log_accuracy.json
-rw-r--r-- <span class="m">1</span> anton eng  <span class="m">20289</span> Jul  <span class="m">3</span> <span class="m">18</span>:06 mlperf_log_detail.txt
-rw-r--r-- <span class="m">1</span> anton eng   <span class="m">1603</span> Jul  <span class="m">3</span> <span class="m">18</span>:06 mlperf_log_summary.txt
-rw-r--r-- <span class="m">1</span> anton eng <span class="m">860442</span> Jul  <span class="m">3</span> <span class="m">18</span>:06 mlperf_log_trace.json
</pre></div>
</div>
<p><a name="usage_accuracy"></a></p>
</div>
<div class="section" id="running-an-accuracy-test">
<h3>Running an accuracy test<a class="headerlink" href="#running-an-accuracy-test" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ck run program:speech-recognition-pytorch-loadgen --cmd_key=accuracy --skip_print_timers
...
Dataset loaded with 4.36 hours. Filtered 1.02 hours. Number of samples: 2513
Running Loadgen test...

No warnings encountered during test.

No errors encountered during test.
Running accuracy script: /usr/bin/python3 /disk1/homes/anton/CK-TOOLS/mlperf-inference-dividiti.rnnt/inference/v0.7/speech_recognition/rnnt/accuracy_eval.py --log_dir /disk1/homes/anton/CK/ck-mlperf/program/speech-recognition-pytorch-loadgen/tmp --dataset_dir /homes/anton/CK-TOOLS/dataset-librispeech-preprocessed-to-wav-dev-clean/../ --manifest /homes/anton/CK-TOOLS/dataset-librispeech-preprocessed-to-wav-dev-clean/wav-list.json
Dataset loaded with 4.36 hours. Filtered 1.02 hours. Number of samples: 2513
Word Error Rate: 0.07452253714852645
Done!

Execution time: 502.197 sec.

$ cd `ck find program:speech-recognition-pytorch-loadgen`/tmp &amp;&amp; ls -la mlperf_log_*
-rw-r--r-- 1 anton eng  3862427 Jul  3 18:00 mlperf_log_accuracy.json
-rw-r--r-- 1 anton eng    20126 Jul  3 18:00 mlperf_log_detail.txt
-rw-r--r-- 1 anton eng       74 Jul  3 18:00 mlperf_log_summary.txt
-rw-r--r-- 1 anton eng 29738248 Jul  3 18:00 mlperf_log_trace.json
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Intel® LPOT.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>