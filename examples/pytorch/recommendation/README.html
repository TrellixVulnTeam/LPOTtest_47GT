

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Original DLRM README &mdash; Intel® Low Precision Optimization Tool  documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> Intel® Low Precision Optimization Tool
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../welcome.html">Introduction to Intel LPOT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/introduction.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../readme.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/doclist.html">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../CONTRIBUTING.html">Contributing Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../legal_information.html">Legal Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../SECURITY.html">Security Policy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Intel® Low Precision Optimization Tool</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Original DLRM README</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/examples/pytorch/recommendation/README.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="original-dlrm-readme">
<h1>Original DLRM README<a class="headerlink" href="#original-dlrm-readme" title="Permalink to this headline">¶</a></h1>
<p>Please refer <a class="reference external" href="https://github.com/facebookresearch/dlrm/blob/master/README.md">DLRM README</a></p>
</div>
<div class="section" id="step-by-step">
<h1>Step-by-Step<a class="headerlink" href="#step-by-step" title="Permalink to this headline">¶</a></h1>
<p>This document is used to list steps of reproducing PyTorch DLRM tuning zoo result.</p>
<blockquote>
<div><p><strong>Note</strong></p>
<ol class="simple">
<li><p>PyTorch quantization implementation in imperative path has limitation on automatically execution.
It requires to manually add QuantStub and DequantStub for quantizable ops, it also requires to manually do fusion operation.
Intel® Low Precision Optimization Tool has no capability to solve this framework limitation. Intel® Low Precision Optimization Tool supposes user have done these two steps before invoking Intel® Low Precision Optimization Tool interface.
For details, please refer to https://pytorch.org/docs/stable/quantization.html</p></li>
<li><p>Please  ensure your PC have &gt;370G memory to run DLRM</p></li>
</ol>
</div></blockquote>
</div>
<div class="section" id="prerequisite">
<h1>Prerequisite<a class="headerlink" href="#prerequisite" title="Permalink to this headline">¶</a></h1>
<div class="section" id="installation">
<h2>1. Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>Recommend python 3.6 or higher version.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install dependency</span>
pip install -r requirements.txt
</pre></div>
</div>
</div>
<div class="section" id="prepare-dataset">
<h2>2. Prepare Dataset<a class="headerlink" href="#prepare-dataset" title="Permalink to this headline">¶</a></h2>
<p>The code supports interface with the <a class="reference external" href="https://labs.criteo.com/2013/12/download-terabyte-click-logs/">Criteo Terabyte Dataset</a></p>
<ol class="simple">
<li><p>download the raw data files day_0.gz, …,day_23.gz and unzip them.</p></li>
<li><p>Specify the location of the unzipped text files day_0, …,day_23, using –raw-data-file=&lt;path/day&gt; (the day number will be appended automatically), please refer “Run” command.</p></li>
</ol>
</div>
<div class="section" id="prepare-pretrained-model">
<h2>3. Prepare pretrained model<a class="headerlink" href="#prepare-pretrained-model" title="Permalink to this headline">¶</a></h2>
<p>Corresponding pre-trained model is available under <a class="reference external" href="https://creativecommons.org/licenses/by-nc/2.0/">CC-BY-NC license</a> and can be downloaded here <a class="reference external" href="https://dlrm.s3-us-west-1.amazonaws.com/models/tb00_40M.pt">dlrm_emb128_subsample0.0_maxindrange40M_pretrained.pt</a></p>
</div>
</div>
<div class="section" id="run">
<h1>Run<a class="headerlink" href="#run" title="Permalink to this headline">¶</a></h1>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/pytorch/recommendation
python -u dlrm_s_pytorch_tune.py --arch-sparse-feature-size<span class="o">=</span><span class="m">128</span> --arch-mlp-bot<span class="o">=</span><span class="s2">&quot;13-512-256-128&quot;</span> <span class="se">\</span>
      --arch-mlp-top<span class="o">=</span><span class="s2">&quot;1024-1024-512-256-1&quot;</span> --max-ind-range<span class="o">=</span><span class="m">40000000</span> --data-generation<span class="o">=</span>dataset <span class="se">\</span>
      --data-set<span class="o">=</span>terabyte --raw-data-file<span class="o">=</span><span class="si">${</span><span class="nv">data_path</span><span class="si">}</span>/day <span class="se">\ </span>
      --processed-data-file<span class="o">=</span><span class="si">${</span><span class="nv">data_path</span><span class="si">}</span>/terabyte_processed.npz --loss-function<span class="o">=</span>bce --round-targets<span class="o">=</span>True <span class="se">\</span>
      --learning-rate<span class="o">=</span><span class="m">1</span>.0 --mini-batch-size<span class="o">=</span><span class="m">2048</span> --print-freq<span class="o">=</span><span class="m">2048</span> --print-time --test-freq<span class="o">=</span><span class="m">102400</span> <span class="se">\</span>
      --test-mini-batch-size<span class="o">=</span><span class="m">16384</span> --test-num-workers<span class="o">=</span><span class="m">16</span> --memory-map --mlperf-logging <span class="se">\</span>
      --mlperf-auc-threshold<span class="o">=</span><span class="m">0</span>.8025 --mlperf-bin-loader --mlperf-bin-shuffle <span class="se">\</span>
      --load-model<span class="o">=</span><span class="si">${</span><span class="nv">model_path</span><span class="si">}</span> --tune
</pre></div>
</div>
</div>
<div class="section" id="examples-of-enabling-intel-low-precision-optimization-tool">
<h1>Examples of enabling Intel® Low Precision Optimization Tool<a class="headerlink" href="#examples-of-enabling-intel-low-precision-optimization-tool" title="Permalink to this headline">¶</a></h1>
<p>This is a tutorial of how to enable DLRM model with Intel® Low Precision Optimization Tool.</p>
</div>
<div class="section" id="user-code-analysis">
<h1>User Code Analysis<a class="headerlink" href="#user-code-analysis" title="Permalink to this headline">¶</a></h1>
<p>Intel® Low Precision Optimization Tool supports two usages:</p>
<ol class="simple">
<li><p>User specifies fp32 ‘model’, calibration dataset ‘q_dataloader’, evaluation dataset “eval_dataloader” and metrics in tuning.metrics field of model-specific yaml config file.</p></li>
<li><p>User specifies fp32 ‘model’, calibration dataset ‘q_dataloader’ and a custom “eval_func” which encapsulates the evaluation dataset and metrics by itself.</p></li>
</ol>
<p>As DLRM’s matrics is ‘f1’, so customer should provide evaluation function ‘eval_func’, it’s suitable for the second use case.</p>
<div class="section" id="write-yaml-config-file">
<h2>Write Yaml config file<a class="headerlink" href="#write-yaml-config-file" title="Permalink to this headline">¶</a></h2>
<p>In examples directory, there is conf.yaml. We could remove most of items and only keep mandotory item for tuning.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">model</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dlrm</span>
  <span class="nt">framework</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">pytorch</span>

<span class="nt">device</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">cpu</span>

<span class="nt">tuning</span><span class="p">:</span>
  <span class="nt">accuracy_criterion</span><span class="p">:</span>
    <span class="nt">relative</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.01</span>
  <span class="nt">exit_policy</span><span class="p">:</span>
    <span class="nt">timeout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
  <span class="nt">random_seed</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">9527</span>
</pre></div>
</div>
<p>Here we set accuracy target as tolerating 0.01 relative accuracy loss of baseline. The default tuning strategy is basic strategy. The timeout 0 means early stop as well as a tuning config meet accuracy target.</p>
<blockquote>
<div><p><strong>Note</strong> : Intel® Low Precision Optimization Tool does NOT support “mse” tuning strategy for pytorch framework</p>
</div></blockquote>
</div>
<div class="section" id="prepare">
<h2>prepare<a class="headerlink" href="#prepare" title="Permalink to this headline">¶</a></h2>
<p>PyTorch quantization requires two manual steps:</p>
<ol class="simple">
<li><p>Add QuantStub and DeQuantStub for all quantizable ops.</p></li>
<li><p>Fuse possible patterns, such as Linear + Relu.</p></li>
</ol>
<p>It’s intrinsic limitation of PyTorch quantizaiton imperative path. No way to develop a code to automatically do that.
The related code changes please refer to examples/pytorch/recommendation/dlrm_s_pytorch_tune.py.</p>
</div>
<div class="section" id="code-update">
<h2>code update<a class="headerlink" href="#code-update" title="Permalink to this headline">¶</a></h2>
<p>After prepare step is done, we just need update run_squad_tune.py and run_glue_tune.py like below</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DLRM_DataLoader</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loader</span> <span class="o">=</span> <span class="n">loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">batch_size</span>
    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">lS_o_test</span><span class="p">,</span> <span class="n">lS_i_test</span><span class="p">,</span> <span class="n">T</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">:</span>
            <span class="k">yield</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">lS_o_test</span><span class="p">,</span> <span class="n">lS_i_test</span><span class="p">),</span> <span class="n">T</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">DLRM_DataLoader</span><span class="p">(</span><span class="n">test_ld</span><span class="p">)</span>
<span class="n">fuse_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dlrm</span><span class="o">.</span><span class="n">bot_l</span><span class="p">),</span> <span class="mi">2</span><span class="p">):</span>
    <span class="n">fuse_list</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="s2">&quot;bot_l.</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="s2">&quot;bot_l.</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>
<span class="n">dlrm</span> <span class="o">=</span> <span class="n">fuse_modules</span><span class="p">(</span><span class="n">dlrm</span><span class="p">,</span> <span class="n">fuse_list</span><span class="p">)</span>
<span class="n">fuse_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dlrm</span><span class="o">.</span><span class="n">top_l</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
    <span class="n">fuse_list</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="s2">&quot;top_l.</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="s2">&quot;top_l.</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>
<span class="n">dlrm</span> <span class="o">=</span> <span class="n">fuse_modules</span><span class="p">(</span><span class="n">dlrm</span><span class="p">,</span> <span class="n">fuse_list</span><span class="p">)</span>
<span class="n">dlrm</span><span class="o">.</span><span class="n">bot_l</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">QuantStub</span><span class="p">())</span>
<span class="n">dlrm</span><span class="o">.</span><span class="n">bot_l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DeQuantStub</span><span class="p">())</span>
<span class="n">dlrm</span><span class="o">.</span><span class="n">top_l</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">QuantStub</span><span class="p">())</span>
<span class="n">dlrm</span><span class="o">.</span><span class="n">top_l</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dlrm</span><span class="o">.</span><span class="n">top_l</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">DeQuantStub</span><span class="p">())</span>
<span class="kn">from</span> <span class="nn">lpot.experimental</span> <span class="kn">import</span> <span class="n">Quantization</span><span class="p">,</span> <span class="n">common</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">Quantization</span><span class="p">(</span><span class="s2">&quot;./conf.yaml&quot;</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">common</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">dlrm</span><span class="p">)</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">calib_dataloader</span> <span class="o">=</span> <span class="n">eval_dataloader</span>
<span class="n">quantizer</span><span class="o">.</span><span class="n">eval_func</span> <span class="o">=</span> <span class="n">eval_func</span>
<span class="n">quantizer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Intel® LPOT.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>